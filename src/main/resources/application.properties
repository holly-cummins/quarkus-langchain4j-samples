#quarkus.langchain4j.openai.api-key=demo

%dev.quarkus.mailer.mock=false

quarkus.langchain4j.easy-rag.path=src/main/resources/catalog

booking.daystostart=10
booking.daystoend=12

# quarkus.langchain4j.openai.base-url=http://localhost:44655/v1
# Configure openai server to use a specific model
quarkus.langchain4j.openai.chat-model.model-name=gpt-4o
# Choose a low temperature to minimize hallucination
quarkus.langchain4j.openai.chat-model.temperature=0
# Set timeout to 3 minutes (local LLM can be quite slow)
quarkus.langchain4j.openai.timeout=180s
# Enable logging of both requests and responses
quarkus.langchain4j.openai.log-requests=true
quarkus.langchain4j.openai.log-responses=true